{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fundacion\\anaconda3\\envs\\transformers\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\fundacion\\anaconda3\\envs\\transformers\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\fundacion\\.cache\\huggingface\\hub\\models--google--flan-t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback generado:\n",
      "Juan participated in a reunión de equipo where they discussed ideas for a new project. Although Juan had some good ideas, he interrumped to his compaeros several times and didn't mostró interés by escuchar the points of view of the others. At the end, he did not help to resumir the ideas discussed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargar un pipeline de generación de texto\n",
    "feedback_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")  # Modelo preentrenado\n",
    "\n",
    "def generate_soft_skills_feedback(input_text):\n",
    "    \"\"\"\n",
    "    Genera retroalimentación sobre habilidades blandas basada en una descripción.\n",
    "    \n",
    "    Parameters:\n",
    "        input_text (str): Texto de evaluación o situación.\n",
    "\n",
    "    Returns:\n",
    "        str: Feedback sobre habilidades blandas.\n",
    "    \"\"\"\n",
    "    # Crear el prompt para generar feedback\n",
    "    prompt = f\"Analyze the following behavior and provide feedback on soft skills:\\n\\n{input_text}\\n\\nFeedback:\"\n",
    "    \n",
    "    # Generar el resultado\n",
    "    feedback = feedback_pipeline(prompt, max_length=200, num_beams=4, early_stopping=True)\n",
    "    return feedback[0][\"generated_text\"]\n",
    "\n",
    "# Ejemplo de evaluación de habilidades blandas\n",
    "input_text = \"\"\"\n",
    "Juan participó en una reunión de equipo donde se discutían ideas para un proyecto nuevo. \n",
    "Aunque Juan tuvo algunas buenas ideas, interrumpió a sus compañeros varias veces y no mostró interés \n",
    "por escuchar los puntos de vista de los demás. Al final, no ayudó a resumir las ideas discutidas.\n",
    "\"\"\"\n",
    "\n",
    "# Generar retroalimentación\n",
    "feedback = generate_soft_skills_feedback(input_text)\n",
    "print(\"Feedback generado:\")\n",
    "print(feedback)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
